{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport itertools\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\ndata=pd.read_csv('../input/creditcard.csv')\n\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3ed057fc2217e9236701419a2b66d83c727e667b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data.describe()",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data.hist(bins=50, figsize=(20,15), color='deepskyblue')\nplt.show()\ndata.describe()\nclass_explore={0: 'deepskyblue', 1: 'deeppink'}\n\nplt.figure(figsize=(12,6))\nax=sns.countplot(x='Class', data=data, palette=class_explore)\nplt.title('Class Distribution')\nplt.show()\n\n#Counts\ncount_normal=len(data[data['Class']==0])\ncount_fraud=len(data[data['Class']==1])\npercent_normal=count_normal/(len(data))*100\npercent_fraud=count_fraud/(len(data))*100\nprint(\"normal : \",percent_normal,\"% and fraud: \",percent_fraud,\"%\")\n\nf, (ax1,ax2)=plt.subplots(2,1,sharex=True, figsize=(15,8))\nbins=50\nax1.hist(data.Time[data.Class==1],bins=bins, color='deeppink')\nax1.set_title('Fraud')\n\nax2.hist(data.Time[data.Class==0], bins=bins, color='deepskyblue')\nax2.set_title('Normal')\n\nplt.xlabel('Time (in seconds)')\nplt.ylabel('Number of instances')\nplt.show()\n\nf, (ax1,ax2)=plt.subplots(2, 1, sharex=True, figsize=(15,8))\nax1.scatter(data.Time[data.Class==1], data.Amount[data.Class==1], color='deeppink')\nax1.set_title('Fraud')\n\nax2.scatter(data.Time[data.Class==1], data.Amount[data.Class==1], color='deepskyblue')\nax2.set_title('Normal')\n\nplt.xlabel('Time (in Sec)')\nplt.ylabel('Amount')\n\nplt.show()\n\nplt.figure(figsize=(12,6))\nax=sns.boxplot(x='Class' , y='Amount', data=data, palette=class_explore)\nax.set_ylim([0,300])\nplt.title(\"Boxplot Amount vs Class\")\nplt.show()\n\nplt.hist(data['Amount'])\nplt.show()\n\nf, (ax1,ax2)= plt.subplots(1,2, figsize=(15,8))\nsns.heatmap(data.query('Class==1').drop(['Class','Time'],1).corr(),vmax=0.8, square=True, ax=ax1, cmap='YlGnBu')\nax1.set_title('Correlation for frauds')\n\nsns.heatmap(data.query('Class==0').drop(['Class','Time'],1).corr(), vmax=0.8, square=True, ax=ax2, cmap='YlGnBu')\nax2.set_title('Correlation for normal')\n\nplt.show()\n\n\n#starting with ML\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title=\"Confusion Matrix\", cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks=np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n    \n    thresh=cm.max()/2.\n    for i, j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n        plt.text(j,i, cm[i,j], horizontalalignment='center', color='white' if cm[i,j]>thresh else 'black')\n    \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \ndef show_metrics():\n    tp=cm[1,1]\n    fn=cm[1,0]\n    fp=cm[0,1]\n    tn=cm[0,0]\n    precision=tp/(tp+fp)\n    recall=tp/(tp+fn)\n    print('Precision: {:.3f}'.format(precision))\n    print('Recall : {:.3f}'.format(recall))\n    print('F1 Score: {:.3f}'.format((2*precision*recall)/(precision+recall)))\n    \ndef plot_roc():\n    plt.plot(fpr, tpr, label='ROC Curve', linewidth=2)\n    plt.plot([0,1],[0,1],'k--',linewidth=2)\n    plt.xlim([0.0,0.001])\n    plt.ylim([0.0,1.05])\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC Curve')\n    plt.show()\n    \ndef plot_precision_recall():\n    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n    plt.fill_between(recall, precision, step ='post', alpha = 0.2,\n                 color = 'b')\n\n    plt.plot(recall, precision, linewidth=2)\n    plt.xlim([0.0,1])\n    plt.ylim([0.0,1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision Recall Curve')\n    plt.show();\n    \n    \n    \n\nfrom sklearn.model_selection import train_test_split\ntrain_set, test_set=train_test_split(data, test_size=0.1, random_state=42)\n\ndata=train_set\nvalid_data=test_set\n\nfrom sklearn.preprocessing import StandardScaler\ndata['normAmount']=StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n\nf, (ax1,ax2)= plt.subplots(2,1, figsize=(15,8))\n\nsns.kdeplot(data['Amount'], shade=True, ax=ax1, color='red')\nax1.set_title('original Amount KDEPlot')\n\nsns.kdeplot(data['normAmount'], shade=True, ax=ax2, color='blue')\nax2.set_title('Normalized Amount KDEPlot')\n\nplt.show()\n\ndata=data.drop(['Amount','Time'], axis=1)\ndata.describe()\n\n\ny=np.array(data.Class.tolist())\ndata=data.drop('Class',1)\nX=np.array(data.as_matrix())\n\nskf=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor train_index, test_index in skf.split(X,y):\n    X_train, y_train= X[train_index], y[train_index]\n    X_test, y_test= X[test_index], y[test_index]\n\nlog_clf=LogisticRegression()\nlog_clf.fit(X_train, y_train)\ny_pred=log_clf.predict(X_test)\ny_score=log_clf.decision_function(X_test)\n\ncm=confusion_matrix(y_test, y_pred)\nclass_names=[0,1]\nplt.figure()\nplot_confusion_matrix(cm, classes=class_names, title='LOGISTIC REGRESSION CONFUSION MATRIX')\nplt.show()\nshow_metrics()\n\nfpr, tpr, t=roc_curve(y_test, y_score)\nplot_roc()\n\nprecision, recall, thresholds=precision_recall_curve(y_test, y_score)\nplot_precision_recall()\n\nfrom pprint import pprint\nprint('Parameters being used: \\n')\npprint(log_clf.get_params())\n\n\n\n",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "177203a0561b46d7bc57894feb8a6ab5a35c9571",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV\nparam_grid={\n    'penalty': ['l1','l2'],\n    'class_weight':['balanced', None],\n    'C': [0.1,1,10, 100]\n}\n\nCV_log_clf=GridSearchCV(estimator=log_clf, param_grid= param_grid, scoring= 'recall', verbose=1, n_jobs=-1)\nCV_log_clf.fit(X_train, y_train)\nbest_params=CV_log_clf.best_params_\nprint('Best parameters: ',best_params)\n",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d2cd559dc669e7d146bf564377c2220643158a4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#logistic regression with best hyperparameters\nlog_clf=LogisticRegression(C=best_params['C'], penalty=best_params['penalty'], class_weight=best_params['class_weight'])\nlog_clf.fit(X_train, y_train)\ny_pred=log_clf.predict(X_test)\ny_score=log_clf.decision_function(X_test)\n\n#confusion matrix and metrics\ncm=confusion_matrix(y_test, y_pred)\nclass_names=[0,1]\nplt.figure()\nplot_confusion_matrix(cm, classes=class_names, title='LOG with best hyperparameters')\nplt.show()\n\nshow_metrics()\n\nfpr_log, tpr_log, t_log= roc_curve(y_test, y_score)\nplot_roc()\n\nprecision_log, recall_log, thresholds_log=precision_recall_curve(y_test, y_score)\nplot_precision_recall()\n\n\n",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8548fbe684d1d06a9929ab28965f1d8e9d9b17ae",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "xgb_clf=xgb.XGBClassifier(n_jobs=-1)\nxgb_clf.fit(X_train,y_train)\ny_pred=xgb_clf.predict(X_test)\ny_score=xgb_clf.predict_proba(X_test)[:,1]\n\ncm=confusion_matrix(y_test, y_pred)\nclass_names=[0,1]\nplt.figure()\nplot_confusion_matrix(cm, classes=class_names, title='XGB Confusion Matrix')\nplt.show()\n\nshow_metrics()\n\nfpr_xgb, tpr_xgb, t_xgb=roc_curve(y_test, y_score)\nplot_roc()\n\nprecision_xgb, recall_xgb, thresholds_xgb=precision_recall_curve(y_test, y_score)\nplot_precision_recall()\n\n\n\n",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7db080d13aac6ae98f2c5432171d28a255440392",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "param_grid={\n    'n_estimators': [100, 200, 300, 400]\n    \n}\nfit_params={'early_stopping_rounds': [100]}\n\nCV_xgb_clf=GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring='f1', verbose=2)\neval_set=[(X_test,y_test)]\nCV_xgb_clf.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"logloss\", eval_set=eval_set, verbose=True)\n\nbest_params_xgb=CV_xgb_clf.best_params_\nprint(\"Best parameters: \",best_params)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "56e1b0dbd16ab0032ce30b5dc8b3305705b7013c"
      },
      "cell_type": "code",
      "source": "rf_clf=RandomForestClassifier(n_jobs=-1, random_state=42)\nrf_clf.fit(X_train, y_train)\ny_pred=rf_clf.predict(X_test)\ny_score=rf_clf.predict_proba(X_test)[:,1]\n\ncm=confusion_matrix(y_test, y_pred)\nclass_names=[0,1]\nplot_confusion_matrix(cm, classes=class_names, title='RF Confusion Matrix')\nplt.show()\nshow_metrics()\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}